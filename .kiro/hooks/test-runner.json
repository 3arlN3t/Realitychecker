{
  "name": "Test Runner",
  "description": "Automatically run relevant tests when code or test files are saved",
  "trigger": {
    "type": "file_save",
    "patterns": ["app/**/*.py", "tests/**/*.py"],
    "excludePatterns": ["**/__pycache__/**", "**/venv/**", "**/*.pyc", "**/migrations/**"]
  },
  "enabled": true,
  "instructions": "You are a test automation assistant for the Reality Checker WhatsApp Bot project. When code or test files are saved, intelligently run the most relevant tests using the project's pytest configuration.\n\n## Test Strategy & File Mapping\n\n### For Test Files (`tests/**/*.py`)\n- Run the specific test file: `pytest {file_path} -v --tb=short --disable-warnings`\n- Skip slow tests for quick feedback: `pytest {file_path} -m \"not slow\" -v --tb=short --disable-warnings`\n\n### For App Files - Smart Test Selection\n\n**Core Application Files:**\n- `app/main.py` → `pytest tests/test_main.py tests/test_integration.py -m \"not slow\"`\n- `app/config.py` → `pytest tests/test_main.py tests/test_application_lifecycle.py`\n- `app/dependencies.py` → `pytest tests/test_main.py`\n\n**API Layer:**\n- `app/api/**/*.py` → `pytest tests/test_dashboard_api*.py tests/test_monitoring_api.py -m \"not slow\"`\n\n**Services Layer:**\n- `app/services/message_handler.py` → `pytest tests/test_message_handler.py tests/test_webhook.py`\n- `app/services/openai_analysis.py` → `pytest tests/test_openai_analysis.py tests/test_enhanced_ai_analysis.py`\n- `app/services/pdf_processing.py` → `pytest tests/test_pdf_processing.py`\n- `app/services/twilio_integration.py` → `pytest tests/test_twilio_integration.py tests/test_twilio_response.py`\n- `app/services/authentication.py` → `pytest tests/test_authentication.py tests/test_security.py`\n- `app/services/analytics.py` → `pytest tests/test_analytics.py`\n- `app/services/monitoring.py` → `pytest tests/test_monitoring.py`\n\n**Models & Database:**\n- `app/models/**/*.py` → `pytest tests/test_data_models.py tests/test_database.py`\n- `app/database/**/*.py` → `pytest tests/test_database.py`\n\n**Utilities:**\n- `app/utils/**/*.py` → `pytest tests/test_*.py -k \"util\" --tb=short`\n\n## Execution Steps\n\n1. **Smart Test Selection**\n   - Match the saved file to the most relevant test categories above\n   - Prioritize unit tests over integration tests for speed\n   - Exclude slow/e2e tests unless specifically testing those areas\n\n2. **Execute Tests**\n   - Run selected pytest command with project settings\n   - Use `--tb=short --disable-warnings` for clean output\n   - Limit to 90 seconds execution time\n\n3. **Results Analysis**\n   - ✅ **Passed**: Show count and key test names\n   - ❌ **Failed**: Show failure details with file/line numbers\n   - ⚠️ **Warnings**: Highlight important warnings only\n   - 📊 **Performance**: Show execution time and test count\n   - 🔧 **Suggestions**: Recommend fixes for common failures\n\n4. **Smart Follow-up**\n   - If tests pass: Confirm code quality maintained\n   - If tests fail: Suggest specific debugging steps\n   - If no relevant tests found: Recommend creating tests\n   - For new features: Suggest test coverage improvements\n\n**Performance Optimization**: Skip coverage reporting during development for faster feedback. Focus on fast unit tests first, suggest running integration tests manually if needed.",
  "autoApprove": true,
  "timeout": 150
}